{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5Vi9x/7IapaaBFrO2avpk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Learning Rate Scheduler\n","PyTorch provides `torch.optim.lr_scheduler` to adjust the learning rate dynamically.\n","\n","## StepLR (Reduce LR Every Few Epochs)"],"metadata":{"id":"7QyvDH_hmSJ_"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlFSOb_umMx_","executionInfo":{"status":"ok","timestamp":1748514773237,"user_tz":-330,"elapsed":21259,"user":{"displayName":"Meenatchi K V","userId":"15684038064487154879"}},"outputId":"fc3af141-ccb9-4530-ac7b-556e8647fa5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Learning Rate: 0.010000\n","Epoch 2, Learning Rate: 0.010000\n","Epoch 3, Learning Rate: 0.010000\n","Epoch 4, Learning Rate: 0.010000\n","Epoch 5, Learning Rate: 0.001000\n","Epoch 6, Learning Rate: 0.001000\n","Epoch 7, Learning Rate: 0.001000\n","Epoch 8, Learning Rate: 0.001000\n","Epoch 9, Learning Rate: 0.001000\n","Epoch 10, Learning Rate: 0.000100\n"]}],"source":["import torch\n","import torch.optim as optim\n","\n","# Define a simple model\n","model = torch.nn.Linear(10, 1)\n","\n","# Define optimizer\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","# Define learning rate scheduler\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","# Training loop\n","for epoch in range(10):\n","    optimizer.step()  # Simulate training step\n","    scheduler.step()  # Update learning rate\n","    print(f\"Epoch {epoch+1}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n"]},{"cell_type":"markdown","source":["## Exponential Decay"],"metadata":{"id":"qhCXuJsTm_aI"}},{"cell_type":"code","source":["scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)"],"metadata":{"id":"TyFeOPs3mad_","executionInfo":{"status":"ok","timestamp":1748514907523,"user_tz":-330,"elapsed":44,"user":{"displayName":"Meenatchi K V","userId":"15684038064487154879"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Cosine Annealing"],"metadata":{"id":"NIZAtalinC7I"}},{"cell_type":"code","source":["scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n"],"metadata":{"id":"4jemluSInCRi","executionInfo":{"status":"ok","timestamp":1748514922878,"user_tz":-330,"elapsed":6,"user":{"displayName":"Meenatchi K V","userId":"15684038064487154879"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Weight Initialization\n","\n","Proper weight initialization helps prevent vanishing/exploding gradients."],"metadata":{"id":"MstV-iMenG45"}},{"cell_type":"markdown","source":["## Xavier Initialization (Glorot)"],"metadata":{"id":"X20jmLl2nKap"}},{"cell_type":"code","source":["import torch.nn as nn\n","\n","def init_weights(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.xavier_uniform_(m.weight)\n","\n","# Apply initialization\n","model.apply(init_weights)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p9i5ofWxnGB8","executionInfo":{"status":"ok","timestamp":1748514951113,"user_tz":-330,"elapsed":16,"user":{"displayName":"Meenatchi K V","userId":"15684038064487154879"}},"outputId":"cecae79b-11c4-4fa3-c850-200ac82609d1"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=10, out_features=1, bias=True)"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## He Initialization (Kaiming)"],"metadata":{"id":"X8jFjyp9nN4p"}},{"cell_type":"code","source":["def init_weights(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n","\n","model.apply(init_weights)\n"],"metadata":{"id":"jAbpnCDunM7C","executionInfo":{"status":"ok","timestamp":1748514962945,"user_tz":-330,"elapsed":54,"user":{"displayName":"Meenatchi K V","userId":"15684038064487154879"}},"outputId":"6c39cac5-18f5-46ce-f407-246a9abfaaaa","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=10, out_features=1, bias=True)"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Zero Initialization (Not Recommended)"],"metadata":{"id":"QWe6N6SKnQzS"}},{"cell_type":"code","source":["def init_weights(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.zeros_(m.weight)\n","\n","model.apply(init_weights)\n"],"metadata":{"id":"jU_CuNDInPzR","executionInfo":{"status":"ok","timestamp":1748514974122,"user_tz":-330,"elapsed":5,"user":{"displayName":"Meenatchi K V","userId":"15684038064487154879"}},"outputId":"917dcd40-024a-41a9-f6b3-aadd100a4e2b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=10, out_features=1, bias=True)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":[],"metadata":{"id":"0NG4erFynSia"},"execution_count":null,"outputs":[]}]}